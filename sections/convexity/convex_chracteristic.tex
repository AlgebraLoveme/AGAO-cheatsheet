\section{Characterizations of Convex Functions}

\subsection{First-order Characterization}
\textbf{Theorem:}
Let $S$ be an open convex subset of $\mathbb{R}^{n}$, and let $f: S \rightarrow \mathbb{R}$ be a differentiable function. Then, $f$ is convex if and only if for any $\boldsymbol{x}, \boldsymbol{y} \in S$ we have that $f(\boldsymbol{y}) \geq f(\boldsymbol{x})+$ $\boldsymbol{\nabla} f(\boldsymbol{x})^{\top}(\boldsymbol{y}-\boldsymbol{x}) .$

\subsection{Second-order Characterization}
\textbf{Theorem}:
Let $S \subseteq \mathbb{R}^{n}$ be open and convex, and let $f: S \rightarrow \mathbb{R}$ be twice continuously differentiable.
\begin{enumerate}
    \item $H_{f}(\boldsymbol{x})$ is positive semi-definite for any $\boldsymbol{x} \in S$ $\Leftrightarrow$ $f$ is convex on $S$.
    \item If $H_{f}(\boldsymbol{x})$ is positive definite for any $\boldsymbol{x} \in S$ then $f$ is strictly convex on $S$. The opposite is not true, \eg, for $f(x)=x^4$ at $x=0$.
\end{enumerate}

\section{Gradient Descent}

\textbf{Theorem:}Let $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ be a $\beta$-gradient Lipschitz, convex function. Let $\boldsymbol{x}_{0}$ be a given starting point, and let $\boldsymbol{x}^{*} \in \arg \min _{x \in \mathbb{R}^{n}} f(\boldsymbol{x})$ be a minimizer of $f$. The Gradient Descent algorithm given by
$$
\boldsymbol{x}_{i+1}=\boldsymbol{x}_{i}-\frac{1}{\beta} \boldsymbol{\nabla} f\left(\boldsymbol{x}_{i}\right)
$$
ensures that the kth iterate satisfies
$$
f\left(\boldsymbol{x}_{k}\right)-f\left(\boldsymbol{x}^{*}\right) \leq \frac{2 \beta\left\|\boldsymbol{x}_{0}-\boldsymbol{x}^{*}\right\|_{2}^{2}}{k+1} .
$$

\textbf{Theorem} Let $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ be a $\beta$-gradient Lipschitz, convex function. 
The Accelerated Gradient Descent algorithm given by
$$
\begin{aligned}
a_{i} &=\frac{i+1}{2}, A_{i}=\frac{(i+1)(i+2)}{4} \\
\boldsymbol{v}_{0} &=\boldsymbol{x}_{0}-\frac{1}{2 \beta} \boldsymbol{\nabla} f\left(\boldsymbol{x}_{0}\right) \\
\boldsymbol{y}_{i} &=\boldsymbol{x}_{i}-\frac{1}{\beta} \boldsymbol{\nabla} f\left(\boldsymbol{x}_{i}\right) \\
\boldsymbol{x}_{i+1} &=\frac{A_{i} \boldsymbol{y}_{i}+a_{i+1} \boldsymbol{v}_{i}}{A_{i+1}} \\
\boldsymbol{v}_{i+1} &=\boldsymbol{v}_{i}-\frac{a_{i+1}}{\beta} \boldsymbol{\nabla} f\left(\boldsymbol{x}_{i+1}\right)
\end{aligned}
$$
ensures that the kth iterate satisfies
$$
f\left(\boldsymbol{x}_{k}\right)-f\left(\boldsymbol{x}^{*}\right) \leq \frac{2 \beta\left\|\boldsymbol{x}_{0}-\boldsymbol{x}^{*}\right\|_{2}^{2}}{(k+1)(k+2)} .
$$

